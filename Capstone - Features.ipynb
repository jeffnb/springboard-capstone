{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = 'datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sizes = {\"normal\": \"\", \"small\": \"_sm\", \"large\": \"_lg\"}\n",
    "\n",
    "VOCAB_SIZE = \"large\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_DUMP = f\"vocab{vocab_sizes[VOCAB_SIZE]}.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pickle.load(open(os.path.join(DATA_DIRECTORY, VOCAB_DUMP), \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED_CORPUS_DUMP = \"preprocessed_corpus.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pickle.load(open(os.path.join(DATA_DIRECTORY, PREPROCESSED_CORPUS_DUMP), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'woman complain clean hous man trash'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Combined Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUMP_FILE = \"combined_data.p\"\n",
    "data = pickle.load(open(os.path.join(DATA_DIRECTORY, DUMP_FILE), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                                                    1\n",
       "tweet    \"@Nicholas_ted33: Kobe stay talking trash. But...\n",
       "id                                                     203\n",
       "Name: 201, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[201]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load up tokenized tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZED_DUMP = \"tokenized_tweets.p\"\n",
    "tokenized = pickle.load(open(os.path.join(DATA_DIRECTORY, TOKENIZED_DUMP), \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the bag of words matrix with the limited vocabulary chosen from previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=0., max_df=1., vocabulary=list(vocab))\n",
    "cv_matrix = cv.fit_transform(corpus)\n",
    "cv_matrix = cv_matrix.toarray()\n",
    "cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10373"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in all the words that are feature names\n",
    "words = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe of the matrix\n",
    "bow_df = pd.DataFrame(cv_matrix, columns=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>woman</th>\n",
       "      <th>complain</th>\n",
       "      <th>clean</th>\n",
       "      <th>hous</th>\n",
       "      <th>man</th>\n",
       "      <th>trash</th>\n",
       "      <th>boi</th>\n",
       "      <th>dat</th>\n",
       "      <th>cold</th>\n",
       "      <th>tyga</th>\n",
       "      <th>...</th>\n",
       "      <th>kennedi</th>\n",
       "      <th>vyapam</th>\n",
       "      <th>bred</th>\n",
       "      <th>obc</th>\n",
       "      <th>bechari</th>\n",
       "      <th>marina</th>\n",
       "      <th>gana</th>\n",
       "      <th>dhani</th>\n",
       "      <th>dadaji</th>\n",
       "      <th>&lt;UNK&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10373 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   woman  complain  clean  hous  man  trash  boi  dat  cold  tyga  ...  \\\n",
       "0      1         1      1     1    1      1    0    0     0     0  ...   \n",
       "1      0         0      0     0    0      0    1    2     1     1  ...   \n",
       "2      0         0      0     0    0      0    0    0     0     0  ...   \n",
       "3      0         0      0     0    0      0    0    0     0     0  ...   \n",
       "4      0         0      0     0    0      0    0    0     0     0  ...   \n",
       "\n",
       "   kennedi  vyapam  bred  obc  bechari  marina  gana  dhani  dadaji  <UNK>  \n",
       "0        0       0     0    0        0       0     0      0       0      0  \n",
       "1        0       0     0    0        0       0     0      0       0      0  \n",
       "2        0       0     0    0        0       0     0      0       0      0  \n",
       "3        0       0     0    0        0       0     0      0       0      0  \n",
       "4        0       0     0    0        0       0     0      0       0      0  \n",
       "\n",
       "[5 rows x 10373 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kill the unknown column from the vocab\n",
    "bow_df = bow_df.drop(\"<UNK>\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the original data with classification into the new bag of words matrix\n",
    "bow_combined = data.merge(bow_df, left_index=True, right_index=True, suffixes=('_x', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44623 entries, 0 to 44622\n",
      "Columns: 10375 entries, class_x to dadaji\n",
      "dtypes: int64(10374), object(1)\n",
      "memory usage: 3.4+ GB\n"
     ]
    }
   ],
   "source": [
    "bow_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_x                                                     1\n",
       "tweet_x     \"@Nicholas_ted33: Kobe stay talking trash. But...\n",
       "id_x                                                      203\n",
       "woman                                                       0\n",
       "complain                                                    0\n",
       "                                  ...                        \n",
       "bechari                                                     0\n",
       "marina                                                      0\n",
       "gana                                                        0\n",
       "dhani                                                       0\n",
       "dadaji                                                      0\n",
       "Name: 201, Length: 10375, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_combined.loc[201]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "We have to add the suffix to the original data since the column names are found in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_x</th>\n",
       "      <th>tweet_x</th>\n",
       "      <th>id_x</th>\n",
       "      <th>woman</th>\n",
       "      <th>complain</th>\n",
       "      <th>clean</th>\n",
       "      <th>hous</th>\n",
       "      <th>man</th>\n",
       "      <th>trash</th>\n",
       "      <th>boi</th>\n",
       "      <th>...</th>\n",
       "      <th>masla</th>\n",
       "      <th>kennedi</th>\n",
       "      <th>vyapam</th>\n",
       "      <th>bred</th>\n",
       "      <th>obc</th>\n",
       "      <th>bechari</th>\n",
       "      <th>marina</th>\n",
       "      <th>gana</th>\n",
       "      <th>dhani</th>\n",
       "      <th>dadaji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10375 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_x                                            tweet_x  id_x  woman  \\\n",
       "0        2  !!! RT @mayasolovely: As a woman you shouldn't...     0      1   \n",
       "1        1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...     1      0   \n",
       "2        1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...     2      0   \n",
       "3        1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...     3      0   \n",
       "4        1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...     4      0   \n",
       "\n",
       "   complain  clean  hous  man  trash  boi  ...  masla  kennedi  vyapam  bred  \\\n",
       "0         1      1     1    1      1    0  ...      0        0       0     0   \n",
       "1         0      0     0    0      0    1  ...      0        0       0     0   \n",
       "2         0      0     0    0      0    0  ...      0        0       0     0   \n",
       "3         0      0     0    0      0    0  ...      0        0       0     0   \n",
       "4         0      0     0    0      0    0  ...      0        0       0     0   \n",
       "\n",
       "   obc  bechari  marina  gana  dhani  dadaji  \n",
       "0    0        0       0     0      0       0  \n",
       "1    0        0       0     0      0       0  \n",
       "2    0        0       0     0      0       0  \n",
       "3    0        0       0     0      0       0  \n",
       "4    0        0       0     0      0       0  \n",
       "\n",
       "[5 rows x 10375 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save bow to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(bow_combined.iloc[:, 3:], bow_combined['class_x'], test_size=0.33,\n",
    "#                                                   random_state=42, stratify=bow_combined['class_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_DUMP = f\"bow{vocab_sizes[VOCAB_SIZE]}.p\"\n",
    "pickle.dump(bow_combined, open(os.path.join(DATA_DIRECTORY, BOW_DUMP), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., vocabulary=list(vocab))\n",
    "tv_matrix = tv.fit_transform(corpus)\n",
    "tv_matrix = tv_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>woman</th>\n",
       "      <th>complain</th>\n",
       "      <th>clean</th>\n",
       "      <th>hous</th>\n",
       "      <th>man</th>\n",
       "      <th>trash</th>\n",
       "      <th>boi</th>\n",
       "      <th>dat</th>\n",
       "      <th>cold</th>\n",
       "      <th>tyga</th>\n",
       "      <th>...</th>\n",
       "      <th>kennedi</th>\n",
       "      <th>vyapam</th>\n",
       "      <th>bred</th>\n",
       "      <th>obc</th>\n",
       "      <th>bechari</th>\n",
       "      <th>marina</th>\n",
       "      <th>gana</th>\n",
       "      <th>dhani</th>\n",
       "      <th>dadaji</th>\n",
       "      <th>&lt;UNK&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.426186</td>\n",
       "      <td>0.486502</td>\n",
       "      <td>0.480812</td>\n",
       "      <td>0.411279</td>\n",
       "      <td>0.329805</td>\n",
       "      <td>0.269405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250212</td>\n",
       "      <td>0.524596</td>\n",
       "      <td>0.318435</td>\n",
       "      <td>0.384685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10373 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      woman  complain     clean      hous       man     trash       boi  \\\n",
       "0  0.426186  0.486502  0.480812  0.411279  0.329805  0.269405  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.250212   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        dat      cold      tyga  ...  kennedi  vyapam  bred  obc  bechari  \\\n",
       "0  0.000000  0.000000  0.000000  ...      0.0     0.0   0.0  0.0      0.0   \n",
       "1  0.524596  0.318435  0.384685  ...      0.0     0.0   0.0  0.0      0.0   \n",
       "2  0.000000  0.000000  0.000000  ...      0.0     0.0   0.0  0.0      0.0   \n",
       "3  0.000000  0.000000  0.000000  ...      0.0     0.0   0.0  0.0      0.0   \n",
       "4  0.000000  0.000000  0.000000  ...      0.0     0.0   0.0  0.0      0.0   \n",
       "\n",
       "   marina  gana  dhani  dadaji  <UNK>  \n",
       "0     0.0   0.0    0.0     0.0    0.0  \n",
       "1     0.0   0.0    0.0     0.0    0.0  \n",
       "2     0.0   0.0    0.0     0.0    0.0  \n",
       "3     0.0   0.0    0.0     0.0    0.0  \n",
       "4     0.0   0.0    0.0     0.0    0.0  \n",
       "\n",
       "[5 rows x 10373 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tv.get_feature_names()\n",
    "tfidf_df = pd.DataFrame(tv_matrix, columns=vocab)\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kill the unknown column from the vocab\n",
    "tfidf_df = tfidf_df.drop(\"<UNK>\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_full = data.merge(tfidf_df, left_index=True, right_index=True, suffixes=('_x', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_x</th>\n",
       "      <th>tweet_x</th>\n",
       "      <th>id_x</th>\n",
       "      <th>woman</th>\n",
       "      <th>complain</th>\n",
       "      <th>clean</th>\n",
       "      <th>hous</th>\n",
       "      <th>man</th>\n",
       "      <th>trash</th>\n",
       "      <th>boi</th>\n",
       "      <th>...</th>\n",
       "      <th>masla</th>\n",
       "      <th>kennedi</th>\n",
       "      <th>vyapam</th>\n",
       "      <th>bred</th>\n",
       "      <th>obc</th>\n",
       "      <th>bechari</th>\n",
       "      <th>marina</th>\n",
       "      <th>gana</th>\n",
       "      <th>dhani</th>\n",
       "      <th>dadaji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.426186</td>\n",
       "      <td>0.486502</td>\n",
       "      <td>0.480812</td>\n",
       "      <td>0.411279</td>\n",
       "      <td>0.329805</td>\n",
       "      <td>0.269405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10375 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_x                                            tweet_x  id_x     woman  \\\n",
       "0        2  !!! RT @mayasolovely: As a woman you shouldn't...     0  0.426186   \n",
       "1        1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...     1  0.000000   \n",
       "2        1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...     2  0.000000   \n",
       "3        1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...     3  0.000000   \n",
       "4        1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...     4  0.000000   \n",
       "\n",
       "   complain     clean      hous       man     trash       boi  ...  masla  \\\n",
       "0  0.486502  0.480812  0.411279  0.329805  0.269405  0.000000  ...    0.0   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.250212  ...    0.0   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  ...    0.0   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  ...    0.0   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  ...    0.0   \n",
       "\n",
       "   kennedi  vyapam  bred  obc  bechari  marina  gana  dhani  dadaji  \n",
       "0      0.0     0.0   0.0  0.0      0.0     0.0   0.0    0.0     0.0  \n",
       "1      0.0     0.0   0.0  0.0      0.0     0.0   0.0    0.0     0.0  \n",
       "2      0.0     0.0   0.0  0.0      0.0     0.0   0.0    0.0     0.0  \n",
       "3      0.0     0.0   0.0  0.0      0.0     0.0   0.0    0.0     0.0  \n",
       "4      0.0     0.0   0.0  0.0      0.0     0.0   0.0    0.0     0.0  \n",
       "\n",
       "[5 rows x 10375 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save tfidf to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_x                                                     1\n",
       "tweet_x     \"@Nicholas_ted33: Kobe stay talking trash. But...\n",
       "id_x                                                      203\n",
       "woman                                                       0\n",
       "complain                                                    0\n",
       "                                  ...                        \n",
       "bechari                                                     0\n",
       "marina                                                      0\n",
       "gana                                                        0\n",
       "dhani                                                       0\n",
       "dadaji                                                      0\n",
       "Name: 201, Length: 10375, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_full.iloc[201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_DUMP = f\"tfidf{vocab_sizes[VOCAB_SIZE]}.p\"\n",
    "pickle.dump(tfidf_full, open(os.path.join(DATA_DIRECTORY, TFIDF_DUMP), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "MODEL_DUMP = \"w2v.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv = KeyedVectors.load(os.path.join(DATA_DIRECTORY, MODEL_DUMP), mmap=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['woman', 'complain', 'clean', 'hous', 'man', 'trash']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_tweet(model, tokenized_tweet):\n",
    "    \"\"\"\n",
    "    take the trained intersect word2vec model and average it along the whole tweet list\n",
    "    \"\"\"\n",
    "    words = [word for word in tokenized_tweet if word in kv.wv]\n",
    "    if len(words) >= 1:\n",
    "        return np.mean(model[words], axis=0)\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44623"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "tweet_vectors = [average_tweet(kv, t) for t in tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_df = pd.DataFrame.from_records(tweet_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_full = data.merge(vector_df, left_index=True, right_index=True, suffixes=(None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.317924</td>\n",
       "      <td>-0.174421</td>\n",
       "      <td>-0.045998</td>\n",
       "      <td>0.131469</td>\n",
       "      <td>0.153139</td>\n",
       "      <td>0.080083</td>\n",
       "      <td>0.584329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157028</td>\n",
       "      <td>-0.575342</td>\n",
       "      <td>-0.052679</td>\n",
       "      <td>-0.507448</td>\n",
       "      <td>-0.127183</td>\n",
       "      <td>-0.679388</td>\n",
       "      <td>-0.129394</td>\n",
       "      <td>-0.176748</td>\n",
       "      <td>-0.572039</td>\n",
       "      <td>-0.453219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.078156</td>\n",
       "      <td>-0.208762</td>\n",
       "      <td>-0.378451</td>\n",
       "      <td>-0.032828</td>\n",
       "      <td>-0.173598</td>\n",
       "      <td>-0.167060</td>\n",
       "      <td>0.252888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108476</td>\n",
       "      <td>-0.406503</td>\n",
       "      <td>-0.200132</td>\n",
       "      <td>0.043845</td>\n",
       "      <td>0.161172</td>\n",
       "      <td>-0.056986</td>\n",
       "      <td>0.071785</td>\n",
       "      <td>-0.313311</td>\n",
       "      <td>0.081915</td>\n",
       "      <td>-0.199177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.220351</td>\n",
       "      <td>-0.150742</td>\n",
       "      <td>-0.166550</td>\n",
       "      <td>0.115838</td>\n",
       "      <td>-0.122622</td>\n",
       "      <td>-0.177487</td>\n",
       "      <td>0.275816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.271640</td>\n",
       "      <td>0.081974</td>\n",
       "      <td>-0.116680</td>\n",
       "      <td>0.230674</td>\n",
       "      <td>0.222533</td>\n",
       "      <td>0.020707</td>\n",
       "      <td>-0.311411</td>\n",
       "      <td>-0.388627</td>\n",
       "      <td>-0.204376</td>\n",
       "      <td>0.092579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.283788</td>\n",
       "      <td>-0.285060</td>\n",
       "      <td>-0.303382</td>\n",
       "      <td>0.952025</td>\n",
       "      <td>-0.227425</td>\n",
       "      <td>-0.579436</td>\n",
       "      <td>0.594272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106376</td>\n",
       "      <td>0.018728</td>\n",
       "      <td>0.241592</td>\n",
       "      <td>0.328473</td>\n",
       "      <td>-0.488023</td>\n",
       "      <td>-0.616264</td>\n",
       "      <td>0.069447</td>\n",
       "      <td>-0.652167</td>\n",
       "      <td>-0.401744</td>\n",
       "      <td>0.058771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.427031</td>\n",
       "      <td>0.184674</td>\n",
       "      <td>-0.950997</td>\n",
       "      <td>0.251101</td>\n",
       "      <td>0.029121</td>\n",
       "      <td>-0.074548</td>\n",
       "      <td>0.771606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225774</td>\n",
       "      <td>0.212599</td>\n",
       "      <td>-0.077561</td>\n",
       "      <td>0.066444</td>\n",
       "      <td>0.108355</td>\n",
       "      <td>-0.243325</td>\n",
       "      <td>-0.123698</td>\n",
       "      <td>-0.511223</td>\n",
       "      <td>-0.314331</td>\n",
       "      <td>0.015501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                              tweet  id         0  \\\n",
       "0      2  !!! RT @mayasolovely: As a woman you shouldn't...   0 -0.317924   \n",
       "1      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   1 -0.078156   \n",
       "2      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   2  0.220351   \n",
       "3      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   3  0.283788   \n",
       "4      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   4 -0.427031   \n",
       "\n",
       "          1         2         3         4         5         6  ...       190  \\\n",
       "0 -0.174421 -0.045998  0.131469  0.153139  0.080083  0.584329  ...  0.157028   \n",
       "1 -0.208762 -0.378451 -0.032828 -0.173598 -0.167060  0.252888  ... -0.108476   \n",
       "2 -0.150742 -0.166550  0.115838 -0.122622 -0.177487  0.275816  ... -0.271640   \n",
       "3 -0.285060 -0.303382  0.952025 -0.227425 -0.579436  0.594272  ... -0.106376   \n",
       "4  0.184674 -0.950997  0.251101  0.029121 -0.074548  0.771606  ...  0.225774   \n",
       "\n",
       "        191       192       193       194       195       196       197  \\\n",
       "0 -0.575342 -0.052679 -0.507448 -0.127183 -0.679388 -0.129394 -0.176748   \n",
       "1 -0.406503 -0.200132  0.043845  0.161172 -0.056986  0.071785 -0.313311   \n",
       "2  0.081974 -0.116680  0.230674  0.222533  0.020707 -0.311411 -0.388627   \n",
       "3  0.018728  0.241592  0.328473 -0.488023 -0.616264  0.069447 -0.652167   \n",
       "4  0.212599 -0.077561  0.066444  0.108355 -0.243325 -0.123698 -0.511223   \n",
       "\n",
       "        198       199  \n",
       "0 -0.572039 -0.453219  \n",
       "1  0.081915 -0.199177  \n",
       "2 -0.204376  0.092579  \n",
       "3 -0.401744  0.058771  \n",
       "4 -0.314331  0.015501  \n",
       "\n",
       "[5 rows x 203 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44623 entries, 0 to 44622\n",
      "Columns: 203 entries, class to 199\n",
      "dtypes: float64(200), int64(2), object(1)\n",
      "memory usage: 69.1+ MB\n"
     ]
    }
   ],
   "source": [
    "word2vec_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class     0\n",
       "tweet     0\n",
       "id        0\n",
       "0        82\n",
       "1        82\n",
       "         ..\n",
       "195      82\n",
       "196      82\n",
       "197      82\n",
       "198      82\n",
       "199      82\n",
       "Length: 203, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_full.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>2</td>\n",
       "      <td>&amp;#128075; hi-ho http://t.co/FiC4FnRutZ</td>\n",
       "      <td>971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>2</td>\n",
       "      <td>1-800-slap-a-hoe</td>\n",
       "      <td>2251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2965</th>\n",
       "      <td>2</td>\n",
       "      <td>@DannyMndz93 @Titan21Mtzzz he's still a pogue ...</td>\n",
       "      <td>3037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>2</td>\n",
       "      <td>@EricBaetsle your a greaser</td>\n",
       "      <td>3206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>2</td>\n",
       "      <td>@FunnyPicsDepot he's a greaser</td>\n",
       "      <td>3299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43688</th>\n",
       "      <td>2</td>\n",
       "      <td>&amp;#128075; hi-ho http://t.co/FiC4FnRutZ</td>\n",
       "      <td>141766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43716</th>\n",
       "      <td>2</td>\n",
       "      <td>Clic Ê__ https://t.co/JLF0Oi54gp Ê‰ÛÏ‰ÛÒÊ‰Û...</td>\n",
       "      <td>141834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43919</th>\n",
       "      <td>2</td>\n",
       "      <td>@justinbieber you are in my journal</td>\n",
       "      <td>142308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43988</th>\n",
       "      <td>2</td>\n",
       "      <td>@Swirley1 @AzTec_Ashy @TeamRetroEU he's back</td>\n",
       "      <td>142462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44330</th>\n",
       "      <td>2</td>\n",
       "      <td>@brittbritt_naay &amp;#128514; I'm a wexican</td>\n",
       "      <td>143233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                              tweet      id   0  \\\n",
       "950        2             &#128075; hi-ho http://t.co/FiC4FnRutZ     971 NaN   \n",
       "2206       2                                   1-800-slap-a-hoe    2251 NaN   \n",
       "2965       2  @DannyMndz93 @Titan21Mtzzz he's still a pogue ...    3037 NaN   \n",
       "3127       2                        @EricBaetsle your a greaser    3206 NaN   \n",
       "3215       2                     @FunnyPicsDepot he's a greaser    3299 NaN   \n",
       "...      ...                                                ...     ...  ..   \n",
       "43688      2             &#128075; hi-ho http://t.co/FiC4FnRutZ  141766 NaN   \n",
       "43716      2  Clic Ê__ https://t.co/JLF0Oi54gp Ê‰ÛÏ‰ÛÒÊ‰Û...  141834 NaN   \n",
       "43919      2                @justinbieber you are in my journal  142308 NaN   \n",
       "43988      2       @Swirley1 @AzTec_Ashy @TeamRetroEU he's back  142462 NaN   \n",
       "44330      2           @brittbritt_naay &#128514; I'm a wexican  143233 NaN   \n",
       "\n",
       "        1   2   3   4   5   6  ...  190  191  192  193  194  195  196  197  \\\n",
       "950   NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2206  NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2965  NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3127  NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3215  NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...    ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "43688 NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "43716 NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "43919 NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "43988 NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "44330 NaN NaN NaN NaN NaN NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       198  199  \n",
       "950    NaN  NaN  \n",
       "2206   NaN  NaN  \n",
       "2965   NaN  NaN  \n",
       "3127   NaN  NaN  \n",
       "3215   NaN  NaN  \n",
       "...    ...  ...  \n",
       "43688  NaN  NaN  \n",
       "43716  NaN  NaN  \n",
       "43919  NaN  NaN  \n",
       "43988  NaN  NaN  \n",
       "44330  NaN  NaN  \n",
       "\n",
       "[82 rows x 203 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_full[word2vec_full[0].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                                      2\n",
       "tweet    @justinbieber you are in my journal\n",
       "id                                    142308\n",
       "0                                        NaN\n",
       "1                                        NaN\n",
       "                        ...                 \n",
       "195                                      NaN\n",
       "196                                      NaN\n",
       "197                                      NaN\n",
       "198                                      NaN\n",
       "199                                      NaN\n",
       "Name: 43919, Length: 203, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_full.loc[43919]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_tweet(kv, tokenized[43919])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly these are just not getting back a vector from the trained system we are going to drop them as they\n",
    "are a small fraction of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_full = word2vec_full.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [class, tweet, id, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 203 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_full[word2vec_full[0].isnull()][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump the word2vec dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD2VECDF_DUMP = \"word2vecdf.p\"\n",
    "pickle.dump(word2vec_full, open(os.path.join(DATA_DIRECTORY, WORD2VECDF_DUMP), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
